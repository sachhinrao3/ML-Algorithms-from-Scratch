{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this project, I have applied a NaiveBayes Algorithm from Scratch and also make prediction with the help of sklearn library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = np.insert(data, 4, target, axis=1)\n",
    "iris_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfi = np.random.permutation(len(iris_data))\n",
    "iris_data = iris_data[sfi]\n",
    "iris_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = iris_data[26:]\n",
    "test_data = iris_data[:25]\n",
    "test_data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='bayes-theorem.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP-1\n",
    "## Seperate by classes \n",
    "def seperate_by_class(dataset):\n",
    "    seperate_data = {}\n",
    "    for i in dataset:\n",
    "        if i[-1] not in seperate_data:\n",
    "            seperate_data[i[-1]] = []\n",
    "        seperate_data[i[-1]].append(i)\n",
    "    return seperate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [array([6.8, 2.8, 4.8, 1.4, 1. ]),\n",
       "  array([5.8, 2.6, 4. , 1.2, 1. ]),\n",
       "  array([5.6, 2.9, 3.6, 1.3, 1. ]),\n",
       "  array([6.4, 2.9, 4.3, 1.3, 1. ]),\n",
       "  array([6.1, 2.9, 4.7, 1.4, 1. ]),\n",
       "  array([6. , 2.2, 4. , 1. , 1. ]),\n",
       "  array([5.4, 3. , 4.5, 1.5, 1. ]),\n",
       "  array([5.7, 2.9, 4.2, 1.3, 1. ]),\n",
       "  array([5. , 2. , 3.5, 1. , 1. ]),\n",
       "  array([7. , 3.2, 4.7, 1.4, 1. ]),\n",
       "  array([5.7, 2.8, 4.1, 1.3, 1. ])],\n",
       " 0.0: [array([5. , 3.3, 1.4, 0.2, 0. ]),\n",
       "  array([4.5, 2.3, 1.3, 0.3, 0. ]),\n",
       "  array([5. , 3.4, 1.5, 0.2, 0. ]),\n",
       "  array([5.1, 3.7, 1.5, 0.4, 0. ]),\n",
       "  array([5. , 3.2, 1.2, 0.2, 0. ]),\n",
       "  array([5.4, 3.4, 1.7, 0.2, 0. ]),\n",
       "  array([4.8, 3.4, 1.9, 0.2, 0. ]),\n",
       "  array([5.8, 4. , 1.2, 0.2, 0. ])],\n",
       " 2.0: [array([6.2, 3.4, 5.4, 2.3, 2. ]),\n",
       "  array([6.3, 2.5, 5. , 1.9, 2. ]),\n",
       "  array([6.7, 3. , 5.2, 2.3, 2. ]),\n",
       "  array([7.9, 3.8, 6.4, 2. , 2. ]),\n",
       "  array([7.7, 3. , 6.1, 2.3, 2. ]),\n",
       "  array([7.7, 2.6, 6.9, 2.3, 2. ])]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperate_by_class(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for class 1.0 is: 0.44\n",
      "The probability for class 0.0 is: 0.32\n",
      "The probability for class 2.0 is: 0.24\n"
     ]
    }
   ],
   "source": [
    "Sep = seperate_by_class(test_data)\n",
    "for i in Sep:\n",
    "    print('The probability for class', i, 'is: %.2f' %(len(Sep[i])/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean(numbers):\n",
    "    return sum(numbers)/len(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Std_values(numbers):\n",
    "    mean = Mean(numbers)\n",
    "    Sum = 0\n",
    "    for i in numbers:\n",
    "        Sum += (i-(mean))**2\n",
    "    stddev = (Sum/len(numbers))**0.5\n",
    "    return stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92480484, 0.47993333, 1.73695826, 0.74074557, 0.74404301])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Std_values(test_data)  ## returns a standard deviation column wise(for each column) and we have 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92480484 0.47993333 1.73695826 0.74074557 0.74404301]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.17402852, 1.91248529, 1.80044439, 1.67020957, 1.67044904,\n",
       "       1.62529997, 1.99939991, 1.92083315, 1.78280678, 1.9405154 ,\n",
       "       1.81614977, 1.92416216, 2.37183473, 1.68689063, 2.26927301,\n",
       "       2.46981781, 1.96020407, 1.91248529, 1.76793665, 1.54919334,\n",
       "       2.03725305, 2.2105203 , 1.84564352, 2.28175371, 1.7565876 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.std(axis=0))\n",
    "test_data.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP-2\n",
    "### summary coonatins mean, Std and the number of dataset in a specific class\n",
    "def Find_summary(datasets):\n",
    "    mean = np.mean(datasets, axis=0)\n",
    "    std = np.std(datasets, axis=0)\n",
    "    All_data = []\n",
    "    for i in zip(mean, std):\n",
    "        a= list(i)\n",
    "        a.append(len(datasets))\n",
    "        All_data.append(a)\n",
    "    return All_data[:-1]   ## We don't want summary of classes column i.e., 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.944000000000001, 0.92480484427797, 25],\n",
       " [3.008, 0.47993332870306055, 25],\n",
       " [3.724000000000001, 1.7369582608686944, 25],\n",
       " [1.164, 0.7407455703546258, 25]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Find_summary(test_data)  ## returns a mean, std for a specific columns in a list format\n",
    "                        ## We have 4 columns and getting a 4 list of summary except last class column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP-3\n",
    "def Manage_Date_By_Class(dataset):\n",
    "    Manage = {}\n",
    "    Sep = seperate_by_class(dataset)\n",
    "    for i in Sep:\n",
    "        Manage[i] = Find_summary(Sep[i])\n",
    "    return Manage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [[5.954545454545454, 0.5662695091780886, 11],\n",
       "  [2.7454545454545456, 0.33673198504458424, 11],\n",
       "  [4.218181818181819, 0.4152068089697904, 11],\n",
       "  [1.281818181818182, 0.1526623238522424, 11]],\n",
       " 0.0: [[5.074999999999999, 0.36314597615834876, 8],\n",
       "  [3.3374999999999995, 0.4580870550452174, 8],\n",
       "  [1.4625, 0.22878756522153906, 8],\n",
       "  [0.2375, 0.06959705453537528, 8]],\n",
       " 2.0: [[7.083333333333335, 0.7033649282003065, 6],\n",
       "  [3.0500000000000003, 0.4462809279665294, 6],\n",
       "  [5.833333333333333, 0.6847546194724713, 6],\n",
       "  [2.1833333333333336, 0.16749792701868146, 6]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manage_Date_By_Class(test_data)  ## Returns a class wise summary for each row or dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiyebayes using gaussian   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='index.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP-4\n",
    "### we divided above formulae into 2 parts\n",
    "### first one is lower part and second one is exponential part\n",
    "def Calculate_probability(x, Mean, Std):\n",
    "    part_1 = 1 /(Std *((2*np.pi)**0.5))\n",
    "    part_2 = np.exp((-(x - Mean)**2)/ (2*(Std**2)))\n",
    "    return part_1 * part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1349774162829703"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calculate_probability(7.2, 6.4, 0.4)  ## for 2.0: [[6.3625, 0.41814321709194346, 25] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP-5  ---> Last step\n",
    "### Apply a naive bayes formulae\n",
    "def Find_Probability(datasets, TestData):\n",
    "    total_rows = 0    ## first we find the number of rows\n",
    "    for i in datasets:\n",
    "        total_rows += datasets[i][0][-1]  ## it is taking the no. of dataset in each class. As we calculate in summary\n",
    "                                          ## we know in our case total rows are 25\n",
    "    prob = {}\n",
    "    for i in datasets:\n",
    "        prob[i] = datasets[i][0][-1]/total_rows  ## return prob for each class {2.0: 0.32, 1.0: 0.28, 0.0: 0.4}\n",
    "                                                 ## This is our P(O) i.e., prob for each outcomes\n",
    "        class_summary = datasets[i]\n",
    "        for j in range(len(class_summary)):\n",
    "            mean, std, num = class_summary[j]   ## Bcz it has mean, std and no. of dataset in class\n",
    "            x = TestData[j]\n",
    "            Newprob = Calculate_probability(x, mean, std)\n",
    "            prob[i] = prob[i] * Newprob         ## Bcz in our NB formulae we multiply P(each events,En) with P(each class or outcm)  \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [[5.954545454545454, 0.5662695091780886, 11],\n",
       "  [2.7454545454545456, 0.33673198504458424, 11],\n",
       "  [4.218181818181819, 0.4152068089697904, 11],\n",
       "  [1.281818181818182, 0.1526623238522424, 11]],\n",
       " 0.0: [[5.074999999999999, 0.36314597615834876, 8],\n",
       "  [3.3374999999999995, 0.4580870550452174, 8],\n",
       "  [1.4625, 0.22878756522153906, 8],\n",
       "  [0.2375, 0.06959705453537528, 8]],\n",
       " 2.0: [[7.083333333333335, 0.7033649282003065, 6],\n",
       "  [3.0500000000000003, 0.4462809279665294, 6],\n",
       "  [5.833333333333333, 0.6847546194724713, 6],\n",
       "  [2.1833333333333336, 0.16749792701868146, 6]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = Manage_Date_By_Class(test_data)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0.02549300805484946,\n",
       " 0.0: 1.987953432469493e-110,\n",
       " 2.0: 7.174797642254352e-07}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = Find_Probability(summary, test_data[21])  ## returns the probabilty that data set belongs to that class\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class = []\n",
    "Prob = []\n",
    "for i in out:\n",
    "    Class.append(int(i))\n",
    "    Prob.append(float(out[i]))\n",
    "pred = Class[Prob.index(max(Prob))]  ## returns the class have max probability\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5. , 3.3, 1.4, 0.2, 0. ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model did a correct prediction. By this we can predict the class for single dataset.\n",
    "\n",
    "### Let's try to make prediction for all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(traindata, testdata):\n",
    "    Summary = Manage_Date_By_Class(traindata)\n",
    "    Allpred = []\n",
    "    \n",
    "    for data in testdata:\n",
    "        out = Find_Probability(Summary, data)\n",
    "        Class = []\n",
    "        Prob = []\n",
    "        for i in out:\n",
    "            Class.append(int(i))\n",
    "            Prob.append(float(out[i]))\n",
    "        ypred = Class[np.argmax(Prob)]\n",
    "        Allpred.append(ypred)\n",
    "    return Allpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 2., 0., 1., 0., 2., 1., 2., 1., 2., 1., 2., 2., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = test_data[:,-1]\n",
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(train_data[:,:-1], train_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test_data[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 2., 0., 1., 0., 2., 1., 2., 1., 2., 1., 2., 2., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "score = accuracy_score(actual, predicted)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0,  0,  6]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model have a good accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
